\documentclass[russian,ignorenonframetext,]{beamer}
\setbeamertemplate{caption}[numbered]
\setbeamertemplate{caption label separator}{: }
\setbeamercolor{caption name}{fg=normal text.fg}
\beamertemplatenavigationsymbolsempty
\usepackage{lmodern}
\usepackage{amssymb,amsmath}
\usepackage{ifxetex,ifluatex}
\usepackage{fixltx2e} % provides \textsubscript
\ifnum 0\ifxetex 1\fi\ifluatex 1\fi=0 % if pdftex
  \usepackage[T1]{fontenc}
  \usepackage[utf8]{inputenc}
\else % if luatex or xelatex
  \ifxetex
    \usepackage{mathspec}
  \else
    \usepackage{fontspec}
  \fi
  \defaultfontfeatures{Ligatures=TeX,Scale=MatchLowercase}
\fi
\usetheme{Madrid}
\usecolortheme{whale}
% use upquote if available, for straight quotes in verbatim environments
\IfFileExists{upquote.sty}{\usepackage{upquote}}{}
% use microtype if available
\IfFileExists{microtype.sty}{%
\usepackage{microtype}
\UseMicrotypeSet[protrusion]{basicmath} % disable protrusion for tt fonts
}{}
\ifnum 0\ifxetex 1\fi\ifluatex 1\fi=0 % if pdftex
  \usepackage[shorthands=off,main=russian]{babel}
\else
  \usepackage{polyglossia}
  \setmainlanguage[]{}
\fi
\newif\ifbibliography
\usepackage{color}
\usepackage{fancyvrb}
\newcommand{\VerbBar}{|}
\newcommand{\VERB}{\Verb[commandchars=\\\{\}]}
\DefineVerbatimEnvironment{Highlighting}{Verbatim}{commandchars=\\\{\}}
% Add ',fontsize=\small' for more characters per line
\usepackage{framed}
\definecolor{shadecolor}{RGB}{248,248,248}
\newenvironment{Shaded}{\begin{snugshade}}{\end{snugshade}}
\newcommand{\KeywordTok}[1]{\textcolor[rgb]{0.13,0.29,0.53}{\textbf{{#1}}}}
\newcommand{\DataTypeTok}[1]{\textcolor[rgb]{0.13,0.29,0.53}{{#1}}}
\newcommand{\DecValTok}[1]{\textcolor[rgb]{0.00,0.00,0.81}{{#1}}}
\newcommand{\BaseNTok}[1]{\textcolor[rgb]{0.00,0.00,0.81}{{#1}}}
\newcommand{\FloatTok}[1]{\textcolor[rgb]{0.00,0.00,0.81}{{#1}}}
\newcommand{\ConstantTok}[1]{\textcolor[rgb]{0.00,0.00,0.00}{{#1}}}
\newcommand{\CharTok}[1]{\textcolor[rgb]{0.31,0.60,0.02}{{#1}}}
\newcommand{\SpecialCharTok}[1]{\textcolor[rgb]{0.00,0.00,0.00}{{#1}}}
\newcommand{\StringTok}[1]{\textcolor[rgb]{0.31,0.60,0.02}{{#1}}}
\newcommand{\VerbatimStringTok}[1]{\textcolor[rgb]{0.31,0.60,0.02}{{#1}}}
\newcommand{\SpecialStringTok}[1]{\textcolor[rgb]{0.31,0.60,0.02}{{#1}}}
\newcommand{\ImportTok}[1]{{#1}}
\newcommand{\CommentTok}[1]{\textcolor[rgb]{0.56,0.35,0.01}{\textit{{#1}}}}
\newcommand{\DocumentationTok}[1]{\textcolor[rgb]{0.56,0.35,0.01}{\textbf{\textit{{#1}}}}}
\newcommand{\AnnotationTok}[1]{\textcolor[rgb]{0.56,0.35,0.01}{\textbf{\textit{{#1}}}}}
\newcommand{\CommentVarTok}[1]{\textcolor[rgb]{0.56,0.35,0.01}{\textbf{\textit{{#1}}}}}
\newcommand{\OtherTok}[1]{\textcolor[rgb]{0.56,0.35,0.01}{{#1}}}
\newcommand{\FunctionTok}[1]{\textcolor[rgb]{0.00,0.00,0.00}{{#1}}}
\newcommand{\VariableTok}[1]{\textcolor[rgb]{0.00,0.00,0.00}{{#1}}}
\newcommand{\ControlFlowTok}[1]{\textcolor[rgb]{0.13,0.29,0.53}{\textbf{{#1}}}}
\newcommand{\OperatorTok}[1]{\textcolor[rgb]{0.81,0.36,0.00}{\textbf{{#1}}}}
\newcommand{\BuiltInTok}[1]{{#1}}
\newcommand{\ExtensionTok}[1]{{#1}}
\newcommand{\PreprocessorTok}[1]{\textcolor[rgb]{0.56,0.35,0.01}{\textit{{#1}}}}
\newcommand{\AttributeTok}[1]{\textcolor[rgb]{0.77,0.63,0.00}{{#1}}}
\newcommand{\RegionMarkerTok}[1]{{#1}}
\newcommand{\InformationTok}[1]{\textcolor[rgb]{0.56,0.35,0.01}{\textbf{\textit{{#1}}}}}
\newcommand{\WarningTok}[1]{\textcolor[rgb]{0.56,0.35,0.01}{\textbf{\textit{{#1}}}}}
\newcommand{\AlertTok}[1]{\textcolor[rgb]{0.94,0.16,0.16}{{#1}}}
\newcommand{\ErrorTok}[1]{\textcolor[rgb]{0.64,0.00,0.00}{\textbf{{#1}}}}
\newcommand{\NormalTok}[1]{{#1}}
\usepackage{longtable,booktabs}
\usepackage{caption}
% These lines are needed to make table captions work with longtable:
\makeatletter
\def\fnum@table{\tablename~\thetable}
\makeatother

% Prevent slide breaks in the middle of a paragraph:
\widowpenalties 1 10000
\raggedbottom

\AtBeginPart{
  \let\insertpartnumber\relax
  \let\partname\relax
  \frame{\partpage}
}
\AtBeginSection{
  \ifbibliography
  \else
    \let\insertsectionnumber\relax
    \let\sectionname\relax
    \frame{\sectionpage}
  \fi
}
\AtBeginSubsection{
  \let\insertsubsectionnumber\relax
  \let\subsectionname\relax
  \frame{\subsectionpage}
}

\setlength{\emergencystretch}{3em}  % prevent overfull lines
\providecommand{\tightlist}{%
  \setlength{\itemsep}{0pt}\setlength{\parskip}{0pt}}
\setcounter{secnumdepth}{0}
\usepackage{etex}
\author[Эконометрика. Неделя 2/15]{Эконометрика. Openedu. Неделя 2}
\newcommand{\e}{\varepsilon}
\newcommand{\hy}{\hat{y}}
\newcommand{\hb}{\hat{\beta}}
\usepackage{lmodern}
\usepackage{tikz}
\usetikzlibrary{decorations.pathmorphing}
\tikzset{snake it/.style={decorate, decoration=snake}}

\title{Статистические свойства оценок}
\date{}

\begin{document}
\frame{\titlepage}

\begin{frame}{Статистические свойства оценок коэффициентов}

\begin{itemize}
\item
  стандартные предпосылки для модели линейной регрессии
\item
  доверительные интервалы для коэффициентов
\item
  гипотезы о коэффициентах
\end{itemize}

\end{frame}

\begin{frame}{Условное математическое ожидание}

\(r\) --- одна случайная величина

\(s\) --- одна случайная величина

\(E(s|r)\) --- это такая функция от случайной величины \(r\), которая
наиболее похожа на случайную величину \(s\)

\end{frame}

\begin{frame}{Условное математическое ожидание. Формально}

\(E(s|r)\) --- это случайная величина \(\tilde{s}\):

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\item
  представимая в виде \(\tilde{s}=f(r)\)
\item
  \(E(\tilde{s})=E(s)\)
\item
  \(Cov(s-\tilde{s},g(r))=0\) для любой \(g(r)\).
\end{enumerate}

Или: \(Cov(s,g(r))=Cov(\tilde{s},g(r))\)

\end{frame}

\begin{frame}{На практике}

Теорема:

Если величина \(r\) дискретна и принимает значения \(a\), \(b\) или
\(c\), то \[
E(s|r)=\begin{cases}
E(s|r=a), \text{ если } r=a \\
E(s|r=b), \text{ если } r=b \\
E(s|r=c), \text{ если } r=c
\end{cases}
\]

\end{frame}

\begin{frame}{Задача {[}у доски{]}}

\begin{longtable}[c]{@{}lll@{}}
\toprule
\(s,r\) & \(r=1\) & \(r=2\)\tabularnewline
\midrule
\endhead
\(s=0\) & 0.25 & 0.2\tabularnewline
\(s=10\) & 0.25 & 0.3\tabularnewline
\bottomrule
\end{longtable}

Найдите: \(E(s|r)\), \(E(s^2|r)\)

\end{frame}

\begin{frame}{Если величины непрерывны и есть совместная функция
плотности}

Теорема:

Если пара величин \(x\), \(y\) имеет функцию плотности \(f(r,s)\), то \[
E(s|r)=\int_{-\infty}^{\infty} s \cdot f(s|r) dx
\]

где \(f(s|r)=f(r,s)/f(r)\) --- условная функция плотности

\end{frame}

\begin{frame}{Свойства условного ожидания}

Пусть \(a\), \(b\) --- константы, \(s\), \(r\) --- случайные величины.

Идея: свойства \(E(s|r)\) аналогичны свойствам \(E(s)\), если считать
\(r\) и любую функцию \(h(r)\) константой.

\end{frame}

\begin{frame}{Свойства условного ожидания}

\begin{itemize}
\item
  \(E(E(s|r))=E(s)\)
\item
  \(E(as+b|r)=aE(s|r)+b\)
\item
  \(E(h(r)|r)=h(r)\)
\item
  \(E(h(r)s|r)=h(r)E(s|r)\)
\end{itemize}

\end{frame}

\begin{frame}{Условная дисперсия и ковариация}

Обычная дисперсия: \(Var(s)=E(s^2)-(E(s))^2\)

Условная дисперсия. \(Var(s|r)=E(s^2|r)-(E(s|r))^2\)

Обычная ковариация: \(Cov(s_1,s_2)=E(s_1 s_2)-E(s_1)E(s_2)\)

Условная ковариация: \(Cov(s_1,s_2|r)=E(s_1 s_2|r)-E(s_1|r)E(s_2|r)\)

\end{frame}

\begin{frame}{Задача {[}у доски{]}}

\begin{longtable}[c]{@{}lll@{}}
\toprule
\(s,r\) & \(r=1\) & \(r=2\)\tabularnewline
\midrule
\endhead
\(s=0\) & 0.25 & 0.2\tabularnewline
\(s=10\) & 0.25 & 0.3\tabularnewline
\bottomrule
\end{longtable}

Найдите: \(Var(s|r)\)

\end{frame}

\begin{frame}{Свойства условной дисперсии}

Пусть \(a\), \(b\) --- константы, \(s\), \(r\) --- случайные величины.

Идея: свойства \(Var(s|r)\) аналогичны свойствам \(Var(s)\), если
считать \(r\) и любую функцию \(h(r)\) константой.

\end{frame}

\begin{frame}{Свойства условной дисперсии}

\(Var(as+b|r)=a^2Var(s|r)\)

\(Var(s+h(r)|r)=Var(s|r)\)

\(Var(h(r)s|r)=h^2(r)Var(s|r)\)

\(Var(s)=Var(E(s|r))+E(Var(s|r))\)

\end{frame}

\begin{frame}{Геометрическая интерпретация {[}у доски{]}}

\begin{figure}
\begin{tikzpicture}
\draw [->, thick] (0,0) -- (3,3);
\draw [->, thick] (0,0) -- (3,0);
\draw [blue] (0,0) -- (5,2);
\draw [blue] (0,0) -- (4,-1.5);
\draw [draw=blue,snake it] (4,-1.5) -- (5,2);
\draw [dashed, thick] (3,3) -- (3,0);
\node [above] at (2.8,2.8) {$s$};
\node [below] at (3,0) {$E(s|r)$};
\node [above] at (4,0.8) {$\{f(r)\}$};
\end{tikzpicture}
\end{figure}

\end{frame}

\begin{frame}{Мораль геометрической интерпретации:}

Если считать, что \(Cov(r,s)\) --- скалярное произведение, то

\begin{itemize}
\item
  квадрат длины случайной величины \(r\) --- дисперсия, \(Var(r)\)
\item
  косинус угла между случайными величинами --- корреляция, \(Corr(s,r)\)
\end{itemize}

Верны ``школьные'' теоремы: теорема Пифагора, Фалеса, etc

\end{frame}

\begin{frame}{Предпосылки на ошибки}

\begin{itemize}
\item
  \(E(\varepsilon_i |X)=0\)
\item
  \(E(\varepsilon_i^2|X)=\sigma^2\) или
  \(Var(\varepsilon_i|X)=\sigma^2\)
\item
  \(E(\varepsilon_i \varepsilon_j|X)=0\) или
  \(Cov(\varepsilon_i,\varepsilon_j|X)=0\)
\end{itemize}

\end{frame}

\begin{frame}{Ковариационная матрица}

Ковариационная матрица вектора \(\varepsilon\):

\[
Var(\varepsilon)=\begin{pmatrix}
Var(\varepsilon_1) & Cov(\varepsilon_1,\varepsilon_2) & Cov(\varepsilon_1,\varepsilon_3) & \ldots \\
Cov(\varepsilon_2,\varepsilon_1) & Var(\varepsilon_2) &  Cov(\varepsilon_2,\varepsilon_3) & \ldots \\
Cov(\varepsilon_3,\varepsilon_1) & Cov(\varepsilon_3,\varepsilon_2) & Var(\varepsilon_3) &   \ldots \\
\vdots & &
\end{pmatrix}
\]

\end{frame}

\begin{frame}{Запись предпосылок с помощью ковариационной матрицы}

\[
Var(\varepsilon|X) = \begin{pmatrix}
\sigma^2 & 0 & 0 & \ldots \\
0 & \sigma^2 & 0 & \ldots \\
0 & 0 & \sigma^2 & \ldots \\
\vdots & \vdots &\vdots  & \\
\end{pmatrix}
= \sigma^2 \begin{pmatrix}
1 & 0 & 0 & \ldots \\
0 & 1 & 0 & \ldots \\
0 & 0 & 1 & \ldots \\
\vdots & \vdots &  \vdots & \\
\end{pmatrix}=\sigma^2 \cdot I_{n\times n}
\]

\end{frame}

\begin{frame}{Дисперсия и ковариация оценок коэффициентов}

Предпосылки:

\begin{itemize}
\tightlist
\item
  \(Var(\varepsilon|X)=\sigma^2 \cdot I_{n\times n}\)
\item
  \(Var(\varepsilon_i|X)=\sigma^2\)
\item
  \(Cov(\varepsilon_i,\varepsilon_j|X)=0\)
\item
  \(y_i=\beta_1 + \beta_2 x_i + \beta_3 z_i +\varepsilon_i\)
\end{itemize}

Позволяют посчитать \(Var(\hat{\beta}_j|X)\),
\(Cov(\hat{\beta}_j,\hat{\beta}_l|X)\)

\end{frame}

\begin{frame}{Пример вычислений в парной регрессии {[}у доски{]}}

В модели \(y_i=\beta_1 + \beta_2 x_i + \varepsilon_i\)

Предположим, что: \(Var(\varepsilon_i|X)=\sigma^2\),
\(Cov(\varepsilon_i, \e_j|X)=0\)

Найдите \(Var(\hat{\beta}_2|X)\),
\(Cov(\hat{\beta}_1,\hat{\beta}_2 |X)\), \(Var(\hat{\beta}_1|X)\)

\end{frame}

\begin{frame}{Итого в парной регрессии:}

\begin{itemize}
\item
  \(Var(\hat{\beta}_2|X)=\frac{\sigma^2}{\sum (x_i-\bar{x})^2}\)
\item
  \(Cov(\hat{\beta}_1,\hat{\beta}_2 |X)=\frac{-\bar{x}\sigma^2}{\sum (x_i-\bar{x})^2}\)
\item
  \(Var(\hat{\beta}_1|X)=\frac{\sigma^2 \sum x_i^2}{n\sum (x_i-\bar{x})^2}\)
\end{itemize}

\end{frame}

\begin{frame}{Вопрос:}

\begin{itemize}
\item
  Зачем придумали эту условную дисперсию, если все свойства аналогичны
  обычной дисперсии?
\item
  А вот как раз и придумали, чтобы всё аналогично просто считалось!
  Настоящая безусловная дисперсия оценок коэффициентов --- гораздо
  сложнее, чем условная.
\end{itemize}

\end{frame}

\begin{frame}{Теорема (без доказательства):}

\[
Var(\hat{\beta}_j| X)=\sigma^2/RSS_j
\] \(RSS_j\) --- сумма квадратов остатков в регрессии \(j\)-ой
объясняющей переменной на остальные объясняющие переменные (включая
константу)

\end{frame}

\begin{frame}{ЛИНАЛ. Ковариационная матрица оценок коэффициентов}

Средствами линейной алгебры можно доказать, что:

\(Var(\hat{\beta}|X)=\sigma^2 (X'X)^{-1}\)

\end{frame}

\begin{frame}{ЛИНАЛ. Предварительная информация к доказательству:}

Свойство: \(Var(Ay)=A\cdot Var(y) \cdot A'\)

Это матричный аналог свойства \(Var(a\cdot y_1)=a^2\cdot Var(y_1)\).

Напомним, что \((AB)'=B'A'\) и \((A^{-1})'=(A')^{-1}\)

Поэтому:

\begin{itemize}
\item
  \((X'X)'=X'X''=X'X\)
\item
  \(((X'X)^{-1})'=(X'X)^{-1}\)
\end{itemize}

\end{frame}

\begin{frame}{ЛИНАЛ. доказательство формулы {[}у доски{]}}

Если оценки МНК существуют и единственны,
\(Var(\varepsilon|X)=\sigma^2 I_{n\times n}\)

то ковариационная матрица равна:

\(Var(\hat{\beta}|X)=\sigma^2 (X'X)^{-1}\)

\end{frame}

\begin{frame}{Как оценить \(\sigma^2\)?}

Константа \(\sigma^2\) неизвестна.

Случайная величина \(\hat{\sigma}^2=\frac{RSS}{n-k}\) --- замечательная
оценка для \(\sigma^2\).

Замечательная в смыслах:

\begin{itemize}
\item
  \(E(\hat{\sigma}^2)=\sigma^2\), в среднем оценивает верно
\item
  \(\hat{\sigma}^2 \to \sigma^2\) по вероятности с ростом \(n\)
\end{itemize}

\end{frame}

\begin{frame}{Оценка ковариационной матрицы}

Идея: заменим во всех формулах \(\sigma^2\) на \(\hat{\sigma}^2\):

\begin{itemize}
\item
  Истинная дисперсия: \(Var(\hat{\beta}_j | X)=\sigma^2 \cdot f(X)\)
\item
  Оценка дисперсии:
  \(\widehat{Var}(\hat{\beta}_j | X)=\hat{\sigma}^2 \cdot f(X)\)
\end{itemize}

а именно: \(\widehat{Var}(\hat{\beta}_j| X)=\hat{\sigma}^2/RSS_j\)

\begin{itemize}
\tightlist
\item
  \(se(\hat{\beta}_j)=\sqrt{\widehat{Var}(\hat{\beta}_j | X)}\)
\end{itemize}

Например, в модели \(y_i=\beta_1 + \beta_2 x_i + \varepsilon_i\):
\(se(\hat{\beta}_2)=\sqrt{\frac{\hat{\sigma}^2}{\sum (x_i-\bar{x})^2}}\)

\end{frame}

\begin{frame}[fragile]{Оценка ковариационной матрицы}

\[
\widehat{Var}(\hat{\beta}|X)=\begin{pmatrix}
\widehat{Var}(\hat{\beta}_1|X) & \widehat{Cov}(\hat{\beta}_1,\hat{\beta}_2|X) & \widehat{Cov}(\hat{\beta}_1,\hat{\beta}_3|X) & \ldots \\
\widehat{Cov}(\hat{\beta}_2,\hat{\beta}_1|X) & \widehat{Var}(\hat{\beta}_2|X) &  \widehat{Cov}(\hat{\beta}_2,\hat{\beta}_3|X) & \ldots \\
\widehat{Cov}(\hat{\beta}_3,\hat{\beta}_1|X) & \widehat{Cov}(\hat{\beta}_3,\hat{\beta}_2|X) & \widehat{Var}(\hat{\beta}_3|X) &   \ldots \\
\vdots & &
\end{pmatrix}
\]

\begin{itemize}
\item
  ЛИНАЛ:
  \(\widehat{Var}(\hat{\beta} | X)=\hat{\sigma}^2 \cdot (X'X)^{-1}\)
\item
  В R: \texttt{vcov(model)}
\end{itemize}

\end{frame}

\begin{frame}{БСХС --- Большой Список Хороших Свойств}

\begin{itemize}
\tightlist
\item
  Базовые:
\end{itemize}

верны даже на малых выборках без предположения о нормальности
\(\varepsilon_i\)

\begin{itemize}
\tightlist
\item
  Асимптотические:
\end{itemize}

верны на больших выборках даже без предположения о нормальности
\(\varepsilon_i\)

\begin{itemize}
\tightlist
\item
  При нормальности:
\end{itemize}

верны при нормальности \(\varepsilon_i\) даже на малых выборках

\end{frame}

\begin{frame}{БСХС --- предположение о связи \(y\) и регрессоров}

Если:

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\tightlist
\item
  Истинная зависимость имеет вид
  \(y_i=\beta_1 + \beta_2 x_i + \beta_3 z_i+\varepsilon_i\)
\end{enumerate}

\begin{itemize}
\tightlist
\item
  В матричном виде: \(y=X\beta + \varepsilon\)
\end{itemize}

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\setcounter{enumi}{1}
\tightlist
\item
  С помощью МНК оценивается регрессия \(y\) на константу, \(x_i\),
  \(z_i\)
\end{enumerate}

\begin{itemize}
\tightlist
\item
  В матричном виде: \(\hat{\beta}=(X'X)^{-1}X'y\)
\end{itemize}

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\setcounter{enumi}{2}
\tightlist
\item
  Наблюдений больше, чем оцениваемых коэффициентов \(\beta\): \(n>k\)
\end{enumerate}

\end{frame}

\begin{frame}{БСХС --- предположения на \(\varepsilon_i\):}

Если:

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\setcounter{enumi}{3}
\tightlist
\item
  Строгая экзогенность:
  \(E(\varepsilon_i | \text{ все регрессоры } )=0\)
\end{enumerate}

\begin{itemize}
\tightlist
\item
  В матричном виде: \(E(\varepsilon_i | X)=0\)
\end{itemize}

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\setcounter{enumi}{4}
\tightlist
\item
  Условная гомоскедастичность:
  \(E(\varepsilon_i^2 | \text{ все регрессоры })=\sigma^2\)
\end{enumerate}

\begin{itemize}
\tightlist
\item
  В матричном виде: \(E(\varepsilon_i^2 | X)=\sigma^2\)
\end{itemize}

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\setcounter{enumi}{5}
\tightlist
\item
  \(Cov(\varepsilon_i,\varepsilon_j | X)=0\) при \(i \neq j\)
\end{enumerate}

\end{frame}

\begin{frame}{БСХС --- предположения на регрессоры}

Если:

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\setcounter{enumi}{6}
\tightlist
\item
  векторы отдельных наблюдений \((x_i,z_i,y_i)\) --- независимы и
  одинаково распределены
\item
  с вероятностью 1 среди регрессоров нет линейно зависимых
\end{enumerate}

\begin{itemize}
\tightlist
\item
  Синонимы в матричном виде: \(rank(X)=k\) или \(det(X'X)\neq 0\) или
  \((X'X)^{-1}\) существует
\end{itemize}

\end{frame}

\begin{frame}{БСХС --- базовые свойства (т. Гаусса-Маркова)}

То:

\begin{itemize}
\item
  Оценки \(\hat{\beta}_j\) линейны по \(y_i\):
  \(\hat{\beta_j}=c_1 y_1 + \ldots + c_n y_n\)
\item
  Оценки несмещены: \(E(\hat{\beta}_j |X )=\beta_j\), и в частности
  \(E(\hat{\beta}_j)=\beta_j\)
\end{itemize}

\end{frame}

\begin{frame}{БСХС --- базовые свойства (т. Гаусса-Маркова)}

То:

\begin{itemize}
\tightlist
\item
  Оценки эффективны среди линейных и несмещенных
\end{itemize}

Для любой линейной по \(y_i\) и несмещенной альтернативной оценки
\(\hat{\beta}^{alt}\):

\(Var(\hat{\beta}_j^{alt} | X)\geq Var(\hat{\beta}_j | X)\) и
\(Var(\hat{\beta}_j^{alt} )\geq Var(\hat{\beta}_j )\)

\end{frame}

\begin{frame}{БСХС --- базовые свойства}

То:

\begin{itemize}
\tightlist
\item
  Ковариационная матрица: \(Var(\hat{\beta} | X )=\sigma^2 (X'X)^{-1}\)
\end{itemize}

Диспрерсии: \(Var(\hat{\beta}_j| X)=\sigma^2/RSS_j\)

\begin{itemize}
\tightlist
\item
  \(Cov(\hat{\beta}_j,\hat{\varepsilon}_i | X)=0\)
\item
  \(E(\hat{\sigma}^2 |X ) = \sigma^2\), и
  \(E(\hat{\sigma}^2 ) = \sigma^2\)
\end{itemize}

\end{frame}

\begin{frame}{БСХС --- асимптотические свойства}

То при \(n\to \infty\):

\begin{itemize}
\tightlist
\item
  \(\hat{\beta}_j \to \beta_j\) по вероятности
\item
  \(\frac{\hat{\beta}_j-\beta_j}{se(\hat{\beta}_j)} \to N(0,1)\) по
  распределению
\item
  \(\hat{\sigma}^2 \to \sigma^2\) по вероятности
\end{itemize}

\(\hat{\sigma}^2=\frac{RSS}{n-k}\)

\end{frame}

\begin{frame}{БСХС --- при нормальности}

Если дополнительно известно, что \(\varepsilon_i \sim N(0, \sigma^2)\),
то:

\begin{itemize}
\tightlist
\item
  Оценки эффективны среди несмещенных
\item
  \(\frac{\hat{\beta}_j-\beta_j}{se(\hat{\beta}_j)}|X \sim t_{n-k}\),
  \(\frac{\hat{\beta}_j-\beta_j}{se(\hat{\beta}_j)}\sim t_{n-k}\)
\item
  \(RSS/\sigma^2 |X \sim \chi^2_{n-k}\),
  \(RSS/\sigma^2 \sim \chi^2_{n-k}\)
\end{itemize}

\end{frame}

\begin{frame}{Доверительные интервалы для коэффициентов}

Возможно строить в двух подходах:

\begin{itemize}
\item
  Асимптотически:
  \(t=\frac{\hat{\beta}_j-\beta_j}{se(\hat{\beta}_j)} \to N(0,1)\)
\item
  При нормальности:
  \(t=\frac{\hat{\beta}_j-\beta_j}{se(\hat{\beta}_j)} \sim t_{n-k}\)
\end{itemize}

Примерный 95\%-ый интервал:

\([\hat{\beta}_j-2se(\hat{\beta}_j);\hat{\beta}_j+2se(\hat{\beta}_j) ]\)

\end{frame}

\begin{frame}{Описание любого теста:}

\begin{itemize}
\tightlist
\item
  предпосылки теста
\end{itemize}

например: асимптотический или требующий нормальности ошибок \(\e_i\)

\begin{itemize}
\tightlist
\item
  проверяемая \(H_0\) против \(H_a\)
\item
  формула для вычисления статистики
\item
  закон распределения статистики при верной \(H_0\)
\end{itemize}

\end{frame}

\begin{frame}{Практическая последовательность действий}

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\tightlist
\item
  выбираем уровень значимости \(\alpha\),
  \(\alpha=P(H_0 \text{ отвергнута }| H_0 \text{ верна })\)
\item
  находим наблюдаемое значение статистики \(S_{obs}\)
\item
  находим критическое значение статистики \(S_{cr}\)
\item
  сравниваем критическое и наблюдаемое \(S_{obs}\) и \(S_{cr}\)
\end{enumerate}

(можно сравнить P-значение и уровень значимости \(\alpha\))

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\setcounter{enumi}{4}
\tightlist
\item
  вывод: ``\(H_0\) отвергается'' или ``\(H_0\) не отвергается''
\end{enumerate}

\end{frame}

\begin{frame}[fragile]{Проверка гипотез и построение доверительных
интервалов {[}у доски{]}}

\begin{Shaded}
\begin{Highlighting}[]
\KeywordTok{summary}\NormalTok{(model)}
            \NormalTok{Estimate Std. Error t value }\KeywordTok{Pr}\NormalTok{(>}\ErrorTok{|}\NormalTok{t|)  }
\NormalTok{(Intercept) }\FloatTok{59.86392}    \FloatTok{3.98754}  \FloatTok{15.013}   \NormalTok{<}\FloatTok{2e-16} \NormalTok{**}\ErrorTok{*}
\NormalTok{Agriculture  }\FloatTok{0.10953}    \FloatTok{0.07848}   \FloatTok{1.396}   \FloatTok{0.1698}    
\NormalTok{Catholic     }\FloatTok{0.11496}    \FloatTok{0.04274}   \FloatTok{2.690}   \FloatTok{0.0101} \NormalTok{*}

\NormalTok{Residual standard error:}\StringTok{ }\FloatTok{11.07}
\end{Highlighting}
\end{Shaded}

\begin{itemize}
\tightlist
\item
  проверьте гипотезу \(\beta_a=0\)
\item
  постройте доверительный интервал для \(\beta_a\)
\item
  постройте доверительный интервал для \(\sigma^2\)
\end{itemize}

\end{frame}

\begin{frame}{стандартные ошибки часто выписывают под коэффициентами}

\(\widehat{Fertility}_i=\underset{(3.98)}{59.8} + \underset{(0.078)}{0.109} Agriculture_i + \underset{(0.042)}{0.115} Catholic_i\)

\end{frame}

\begin{frame}[fragile]{Стандартная табличка в любом статистическом
пакете {[}у доски{]}}

\begin{Shaded}
\begin{Highlighting}[]
            \NormalTok{Estimate Std. Error t value }\KeywordTok{Pr}\NormalTok{(>}\ErrorTok{|}\NormalTok{t|)   }

\NormalTok{(Intercept) }\FloatTok{59.86392}    \FloatTok{3.98754}  \FloatTok{15.013}   \NormalTok{<}\FloatTok{2e-16} \NormalTok{**}\ErrorTok{*}
\NormalTok{Agriculture  }\FloatTok{0.10953}    \FloatTok{0.07848}   \FloatTok{1.396}   \FloatTok{0.1698}    
\NormalTok{Catholic     }\FloatTok{0.11496}    \FloatTok{0.04274}   \FloatTok{2.690}   \FloatTok{0.0101} \NormalTok{*}
\end{Highlighting}
\end{Shaded}

\end{frame}

\begin{frame}{Особые моменты при проверки гипотез}

\begin{itemize}
\item
  Плохое устоявшееся название гипотез
\item
  Смысл формулировки ``\(H_0\) не отвергается''
\item
  Значимость и существенность --- разные вещи
\item
  Проблема множественных сравнений
\end{itemize}

\end{frame}

\begin{frame}{Плохое устоявшееся название}

Проверка значимости --- на самом деле проверка незначимости:

\begin{itemize}
\item
  ``Мы проверили значимость коэффициента при доходе''
\item
  Мы проверили \(H_0: \beta_{inc}=0\).
\end{itemize}

\end{frame}

\begin{frame}{Смысл ``\(H_0\) не отвергается''}

\begin{itemize}
\item
  недостаточно данных чтобы отвергнуть \(H_0\)
\item
  имеющиеся данные не противоречат \(H_0\)
\end{itemize}

Вполне возможно, что данные не противоречат \(H_a\) (!)

\end{frame}

\begin{frame}{Значимость и существенность}

\begin{itemize}
\tightlist
\item
  Коэффициент может быть значимым и совершенно несущественным
\end{itemize}

На огромных выборках как правило все коэффиценты значимы

\begin{itemize}
\tightlist
\item
  Коэффициент может быть существенным, но незначимым
\end{itemize}

Значимость --- статистическое отвержение гипотезы о точном равенстве

Существенность --- насколько данное отличие от нуля важно в прикладном
смысле

\end{frame}

\begin{frame}{Стандартизированные коэффициенты}

Существенность --- можно придать разный математический смысл

Например:

\begin{itemize}
\tightlist
\item
  стандартизировать переменные:
\end{itemize}

\(y^{st}_i:= \frac{y_i-\bar{y}}{sd(y)}\),
\(x^{st}_i:= \frac{x_i-\bar{x}}{sd(x)}\),
\(z^{st}_i:= \frac{z_i-\bar{z}}{sd(z)}\)

\begin{itemize}
\tightlist
\item
  переоценить модель:
\end{itemize}

\(y^{st}_i=\beta_1^{st}+\beta_2^{st}x_i^{st}+\beta_3^{st}z_i^{st}+\varepsilon_i^{st}\)

\end{frame}

\begin{frame}{Проблема множественных сравнений}

\begin{itemize}
\item
  Исследователь хочет проверить гипотезу о том, что \(\beta_{42}=0\).
  Ok.
\item
  Исследователь хочет выяснить какие регрессоры из 100 значимы. Плохой
  метод.
\end{itemize}

\end{frame}

\begin{frame}{Проверка гипотезы об одном ограничении}

Хотим проверить гипотезу о \(\beta_2-\beta_3\).

Статистика
\(t=\frac{\hat{\beta}_2-\hat{\beta}_3-(\beta_2-\beta_3)}{se(\hat{\beta}_2-\hat{\beta}_3)}\)
распределена

\begin{itemize}
\item
  асимптитически \(N(0,1)\)
\item
  при нормальности \(t_{n-k}\)
\end{itemize}

\end{frame}

\begin{frame}{Переформулировка модели}

Хотим проверить гипотезу \(\beta_2=\beta_3\) или \(\beta_2-\beta_3=0\)

Всегда можно переформулировать модель так, что \(\beta_2-\beta_3\)
станет новым коэффициентом \(\beta_2'=\beta_2-\beta_3\).

\end{frame}

\begin{frame}[fragile]{Пример проверки гипотезы о связи коэффициентов
{[}у доски{]}}

\begin{Shaded}
\begin{Highlighting}[]
\KeywordTok{summary}\NormalTok{(model)}
            \NormalTok{Estimate Std. Error t value }\KeywordTok{Pr}\NormalTok{(>}\ErrorTok{|}\NormalTok{t|)  }
\NormalTok{(Intercept) }\FloatTok{59.86392}    \FloatTok{3.98754}  \FloatTok{15.013}   \NormalTok{<}\FloatTok{2e-16} \NormalTok{**}\ErrorTok{*}
\NormalTok{Agriculture  }\FloatTok{0.10953}    \FloatTok{0.07848}   \FloatTok{1.396}   \FloatTok{0.1698}    
\NormalTok{Catholic     }\FloatTok{0.11496}    \FloatTok{0.04274}   \FloatTok{2.690}   \FloatTok{0.0101} \NormalTok{*}
\KeywordTok{vcov}\NormalTok{(model)}
             \NormalTok{(Intercept)  Agriculture     Catholic}
\NormalTok{(Intercept) }\FloatTok{15.900471817} \NormalTok{-}\FloatTok{0.256680712} \NormalTok{-}\FloatTok{0.006998292}
\NormalTok{Agriculture -}\FloatTok{0.256680712}  \FloatTok{0.006159437} \NormalTok{-}\FloatTok{0.001345371}
\NormalTok{Catholic    -}\FloatTok{0.006998292} \NormalTok{-}\FloatTok{0.001345371}  \FloatTok{0.001826622}
\NormalTok{Residual standard error:}\StringTok{ }\FloatTok{11.07}
\end{Highlighting}
\end{Shaded}

Проверьте гипотезу \(\beta_a=\beta_c\) (два способа)

\end{frame}

\begin{frame}{Мораль лекции 2:}

В этой лекции мы научились:

\begin{itemize}
\item
  строить доверительные интервалы
\item
  проверять гипотезы об отдельном коэффициенте
\item
  сформулировали стандартные предпосылки
\end{itemize}

В следующей:

\begin{itemize}
\item
  более сложные гипотезы
\item
  прогнозирование
\end{itemize}

\end{frame}

\begin{frame}{Источники мудрости:}

\begin{itemize}
\item
  Артамонов Н.В., Введение в эконометрику: главы 1.3
\item
  Борзых Д.А., Демешев Б.Б. Эконометрика в задачах и упражнениях: глава
  2, 3
\item
  Катышев П.К., Пересецкий А. А. Эконометрика. Начальный курс: главы
  2.4, 2.5, 2.6, 3.2, 3.3
\item
  Себер Дж., Линейный регрессионный анализ: главы 3.2, 3.3, 3.4
\end{itemize}

\end{frame}

\end{document}
